{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BÀI TẬP 1\n",
    "Sinh viên tìm hiểu các thư viện nêu trên (đặc điểm, chức năng, điểm nổi bật, cách thức và lệnh cài đặt) và cho biết thư viện nào hỗ trợ cho NLP.\n",
    "\n",
    "Sinh viên nhập câu trả lời tại đây"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Danh sách các thư viện theo nhóm\n",
    "1. Thư viện tính toán và Machine Learning\n",
    "NumPy\n",
    "Keras\n",
    "Pandas\n",
    "PyTorch\n",
    "TensorFlow\n",
    "\n",
    "2. Thư viện vẽ đồ thị và xử lý ảnh\n",
    "Matplotlib\n",
    "OpenCV\n",
    "Seaborn\n",
    "Scipy\n",
    "Theano\n",
    "SimpleITK\n",
    "Pillow\n",
    "\n",
    "3. Thư viện Web Scraping\n",
    "Selenium\n",
    "Scrapy\n",
    "Requests\n",
    "Beautiful Soup\n",
    "\n",
    "4. Thư viện kiểm thử\n",
    "Pytest\n",
    "Mahotas\n",
    "\n",
    "5. Thư viện hỗ trợ NLP\n",
    "NLTK\n",
    "Scikit-Learn\n",
    "Gensim\n",
    "TextBlob\n",
    "SpaCy\n",
    "Pattern\n",
    "Transformers\n",
    "\n",
    "\n",
    "Dưới đây là bảng tổng hợp thông tin về đặc điểm, chức năng, điểm nổi bật và cách thức cài đặt của các thư viện đã liệt kê.  \n",
    "\n",
    "---\n",
    "\n",
    "### **1. Thư viện tính toán và Machine Learning**  \n",
    "| **Thư viện**  | **Đặc điểm**  | **Chức năng**  | **Điểm nổi bật**  | **Cách cài đặt**  |\n",
    "|--------------|-------------|---------------|----------------|----------------|\n",
    "| **NumPy**  | Xử lý số học và ma trận | Cung cấp mảng đa chiều, phép toán tuyến tính | Hiệu suất cao, sử dụng trong ML & AI | `pip install numpy` |\n",
    "| **Keras**  | Framework Deep Learning | Xây dựng và huấn luyện mô hình học sâu | Giao diện dễ dùng, tích hợp với TensorFlow | `pip install keras` |\n",
    "| **Pandas**  | Xử lý dữ liệu dạng bảng | Quản lý và phân tích dữ liệu | Hỗ trợ DataFrame mạnh mẽ | `pip install pandas` |\n",
    "| **PyTorch**  | Thư viện Deep Learning | Xây dựng và huấn luyện mô hình AI | Linh hoạt, tối ưu GPU | `pip install torch` |\n",
    "| **TensorFlow**  | Deep Learning | Xây dựng và triển khai mô hình học sâu | Google phát triển, hỗ trợ TPU | `pip install tensorflow` |\n",
    "\n",
    "---\n",
    "\n",
    "### **2. Thư viện vẽ đồ thị và xử lý ảnh**  \n",
    "| **Thư viện**  | **Đặc điểm**  | **Chức năng**  | **Điểm nổi bật**  | **Cách cài đặt**  |\n",
    "|--------------|-------------|---------------|----------------|----------------|\n",
    "| **Matplotlib**  | Vẽ đồ thị 2D | Biểu đồ, đồ thị trực quan | Tuỳ chỉnh cao, dễ sử dụng | `pip install matplotlib` |\n",
    "| **OpenCV**  | Xử lý ảnh/video | Nhận diện, phân tích ảnh | Mạnh mẽ, hỗ trợ nhiều định dạng | `pip install opencv-python` |\n",
    "| **Seaborn**  | Vẽ biểu đồ thống kê | Phân tích dữ liệu trực quan | Giao diện đẹp, dễ tùy chỉnh | `pip install seaborn` |\n",
    "| **Scipy**  | Tính toán khoa học | Phép toán ma trận, xử lý tín hiệu | Mở rộng từ NumPy | `pip install scipy` |\n",
    "| **Theano**  | Tính toán tensor | Xây dựng mô hình Deep Learning | Hiệu suất cao, tối ưu GPU | `pip install theano` |\n",
    "| **SimpleITK**  | Xử lý ảnh y tế | Làm việc với ảnh DICOM | Hỗ trợ dữ liệu y tế | `pip install SimpleITK` |\n",
    "| **Pillow**  | Xử lý ảnh | Chỉnh sửa, chuyển đổi định dạng ảnh | Hỗ trợ nhiều loại file ảnh | `pip install pillow` |\n",
    "\n",
    "---\n",
    "\n",
    "### **3. Thư viện Web Scraping**  \n",
    "| **Thư viện**  | **Đặc điểm**  | **Chức năng**  | **Điểm nổi bật**  | **Cách cài đặt**  |\n",
    "|--------------|-------------|---------------|----------------|----------------|\n",
    "| **Selenium**  | Điều khiển trình duyệt | Tự động hoá thao tác web | Hỗ trợ nhiều trình duyệt | `pip install selenium` |\n",
    "| **Scrapy**  | Web crawling | Thu thập dữ liệu web tự động | Tốc độ nhanh, mạnh mẽ | `pip install scrapy` |\n",
    "| **Requests**  | HTTP request | Gửi yêu cầu HTTP/HTTPS | Đơn giản, phổ biến | `pip install requests` |\n",
    "| **BeautifulSoup**  | Phân tích HTML | Trích xuất dữ liệu từ web | Nhẹ, dễ sử dụng | `pip install beautifulsoup4` |\n",
    "\n",
    "---\n",
    "\n",
    "### **4. Thư viện kiểm thử**  \n",
    "| **Thư viện**  | **Đặc điểm**  | **Chức năng**  | **Điểm nổi bật**  | **Cách cài đặt**  |\n",
    "|--------------|-------------|---------------|----------------|----------------|\n",
    "| **Pytest**  | Kiểm thử tự động | Chạy unit test | Đơn giản, mở rộng dễ dàng | `pip install pytest` |\n",
    "| **Mahotas**  | Xử lý ảnh | Trích xuất đặc trưng ảnh | Hỗ trợ phân tích ảnh nhanh | `pip install mahotas` |\n",
    "\n",
    "---\n",
    "\n",
    "### **5. Thư viện hỗ trợ NLP**  \n",
    "| **Thư viện**  | **Đặc điểm**  | **Chức năng**  | **Điểm nổi bật**  | **Cách cài đặt**  |\n",
    "|--------------|-------------|---------------|----------------|----------------|\n",
    "| **NLTK**  | Xử lý ngôn ngữ tự nhiên | Tokenization, stemming, POS tagging | Bộ công cụ NLP đầy đủ | `pip install nltk` |\n",
    "| **Scikit-Learn**  | Machine Learning | Mô hình ML, TF-IDF | Hỗ trợ NLP (vector hóa văn bản) | `pip install scikit-learn` |\n",
    "| **Gensim**  | Mô hình hóa chủ đề | Word2Vec, LDA, LSI | Hiệu suất cao | `pip install gensim` |\n",
    "| **TextBlob**  | Phân tích văn bản | Cảm xúc, dịch ngôn ngữ | Dễ dùng, dựa trên NLTK | `pip install textblob` |\n",
    "| **SpaCy**  | NLP hiệu suất cao | Tokenization, parsing | Nhanh, nhiều mô hình pretrained | `pip install spacy` |\n",
    "| **Pattern**  | Xử lý văn bản & web mining | Trích xuất văn bản, NLP | Hỗ trợ cả xử lý web | `pip install pattern` |\n",
    "| **Transformers**  | Mô hình NLP hiện đại | BERT, GPT, T5 | Tích hợp sẵn mô hình pretrained | `pip install transformers` |\n",
    "\n",
    "---\n",
    "\n",
    "✅ **Các thư viện hỗ trợ NLP**:  \n",
    "**NLTK, Scikit-Learn, Gensim, TextBlob, SpaCy, Pattern, Transformers**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "BÀI TẬP 2\n",
    "Sinh viên chạy thực nghiệm các đoạn code sau và trả lời các câu hỏi:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I love NLP. It's fantastic!\n",
      "0.5\n"
     ]
    }
   ],
   "source": [
    "#Code 1\n",
    "\n",
    "from textblob import TextBlob\n",
    "\n",
    "text = \"I love NLP. It's fantastic!\"\n",
    "\n",
    "blob = TextBlob(text)\n",
    "print(blob) # chạy thử coi nó sao thui\n",
    "\n",
    "sentiment = blob.sentiment.polarity # sentiment trả về mấy cái số (polarity, subjectivity)\n",
    "\n",
    "print(sentiment)\n",
    "\n",
    "# https://textblob.readthedocs.io/en/dev/quickstart.html\n",
    "\"\"\"\n",
    "Thư viện sử dụng trong đoạn code có chức năng gì?\n",
    "    -- The sentiment property returns a namedtuple of the form Sentiment(polarity, subjectivity). \n",
    "    The polarity score is a float within the range [-1.0, 1.0]. \n",
    "    The subjectivity is a float within the range [0.0, 1.0] where 0.0 is very objective and 1.0 is very subjective.\n",
    "    --\n",
    "    Giải thích về Sentiment Analysis trong TextBlob\n",
    "    Polarity (tính phân cực):\n",
    "\n",
    "    Giá trị nằm trong khoảng [-1.0, 1.0].\n",
    "    -1.0: Cảm xúc tiêu cực.\n",
    "    0.0: Trung lập.\n",
    "    1.0: Cảm xúc tích cực.\n",
    "    Subjectivity (tính chủ quan):\n",
    "\n",
    "    Giá trị nằm trong khoảng [0.0, 1.0].\n",
    "    0.0: Rất khách quan (fact-based).\n",
    "    1.0: Rất chủ quan (opinion-based).\n",
    "    --\n",
    "\n",
    "Kết quả chạy thực nghiệm\n",
    "    -- ra kết quả 0.5 \n",
    "Nhận xét kết quả\n",
    "    -- hơi hơi khách quan\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'gensim'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mgensim\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m corpora\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Danh sách các văn bản (documents)\u001b[39;00m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'gensim'"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim import corpora\n",
    "\"\"\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "# Danh sách các văn bản (documents)\n",
    "documents = [\n",
    "    \"Apple and Microsoft are leading technology companies.\",\n",
    "    \"Python and Java are popular programming languages.\",\n",
    "    \"Football and basketball are exciting sports.\"\n",
    "]\n",
    "\n",
    "# Danh sách stopwords (từ không quan trọng)\n",
    "stopwords = {\"and\", \"are\"}\n",
    "\"\"\"stopwords chứa các từ không có ý nghĩa quan trọng như \"and\", \"are\".\n",
    "texts loại bỏ các stopwords khỏi danh sách từ trong mỗi câu\"\"\"\n",
    "# Tiền xử lý văn bản: loại bỏ stopwords và tách từ\n",
    "texts = [\n",
    "    [word for word in doc.split() if word.lower() not in stopwords] \n",
    "    for doc in documents\n",
    "] #[['Apple', 'Microsoft', 'leading', 'technology', 'companies.'], ['Python', 'Java', 'popular', 'programming', 'languages.'], ['Football', 'basketball', 'exciting', 'sports.']]\n",
    "\n",
    "# Tạo từ điển (mỗi từ có một ID duy nhất)\n",
    "dictionary = corpora.Dictionary(texts)\n",
    "\"\"\"Dictionary ánh xạ mỗi từ vào một ID duy nhất.\n",
    "Corpus chuyển đổi văn bản thành dạng bag-of-words (BOW), mỗi từ có số lần xuất hiện.\"\"\"\n",
    "# Chuyển văn bản thành Bag of Words (BoW)\n",
    "corpus = [dictionary.doc2bow(text) for text in texts]\n",
    "\n",
    "# Huấn luyện mô hình LDA với 3 chủ đề (num_topics=3) và 15 vòng lặp (passes=15)\n",
    "lda = gensim.models.LdaModel(corpus, num_topics=3, id2word=dictionary, passes=15)\n",
    "\"\"\"LDA (Latent Dirichlet Allocation) được sử dụng để tìm ra các chủ đề trong văn bản.\n",
    "num_topics=3: Phân loại thành 3 chủ đề.\n",
    "passes=15: Chạy thuật toán 15 lần để cải thiện kết quả.\"\"\"\n",
    "# In ra 3 chủ đề, mỗi chủ đề gồm 3 từ quan trọng\n",
    "print(lda.print_topics(num_topics=3, num_words=3))\n",
    "\n",
    "\"\"\"\n",
    "Thư viện sử dụng trong đoạn code có chức năng gì?\n",
    "    gensim: Một thư viện xử lý NLP mạnh mẽ.\n",
    "    corpora: Dùng để tạo từ điển (dictionary) từ tập dữ liệu văn bản.\n",
    "\n",
    "Kết quả chạy thực nghiệm\n",
    "    [(0, '0.098*\"technology\" + 0.098*\"Microsoft\" + 0.098*\"leading\"'), (1, '0.072*\"basketball\" + 0.072*\"Football\" + 0.072*\"exciting\"'), (2, '0.138*\"Java\" + 0.138*\"Python\" + 0.138*\"programming\"')]\n",
    "    Mô hình LDA đã phân loại chủ đề khá chính xác, dù chỉ có 3 câu văn bản.\n",
    "\n",
    "Nhận xét kết quả\n",
    "    nhận được 3 phân loại thấy cũng khá đúng nếu date nhiều hơn thì ok hơn\n",
    "\"\"\"\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code 3\n",
    "\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\") # Mô hình này giúp phân tích ngữ pháp, gán nhãn từ loại, phân tích mối quan hệ giữa các từ trong câu\n",
    "\n",
    "sentence = \"The cat chased the mouse\"\n",
    "\n",
    "doc = nlp(sentence)\n",
    "\n",
    "for token in doc:\n",
    "\n",
    "print(token.text, \"-->\", token.dep_)\n",
    "\n",
    "\"\"\"\n",
    "Thư viện sử dụng trong đoạn code có chức năng gì?\n",
    "    Thư viện xử lý ngôn ngữ tự nhiên (NLP) mạnh mẽ, giúp phân tích cú pháp câu, nhận diện thực thể, và gán nhãn từ loại.\n",
    "Kết quả chạy thực nghiệm\n",
    "    det: Determiner (mạo từ: \"The\").\n",
    "    nsubj: Nominal Subject (chủ ngữ: \"cat\").\n",
    "    ROOT: Từ gốc của câu (động từ chính: \"chased\").\n",
    "    dobj: Direct Object (tân ngữ trực tiếp: \"mouse\").\n",
    "Nhận xét kết quả\n",
    "    Kết quả đúng với ngữ pháp tiếng Anh.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# BÀI TẬP 3\n",
    "Sinh viên tìm hiểu các nguồn dataset nêu trên và cho biết:\n",
    "\n",
    "- Đặc điểm của từng nguồn.\n",
    "\n",
    "- Bộ dữ liệu công khai trên các nguồn thuộc lĩnh vực gì (nêu rõ từng nguồn).\n",
    "\n",
    "- Dạng dữ liệu công khai.\n",
    "\n",
    "- Ưu điểm, hạn chế (nếu có) của từng nguồn.\n",
    "\n",
    "- Nguồn nào cung cấp dữ liệu cho lĩnh vực NLP.\n",
    "\n",
    "- Chọn 1 bộ dữ liệu để tìm hiểu và cho biết các thông tin cơ bản về bộ dữ liệu (vd: lĩnh vực, số mẫu, kích thước, thuộc tính, ...)\n",
    "\n",
    "- Nêu 01 nguồn cung cấp dữ liệu NLP uy tín (khác với các nguồn nêu trên).\n",
    "\n",
    "Sinh viên nhập câu trả lời tại đây\n",
    "\n",
    "Dưới đây là hướng dẫn chi tiết để em thực hiện bài tập 3 một cách đầy đủ và khoa học:\n",
    "\n",
    "## 1. Đặc điểm của từng nguồn dataset\n",
    "\n",
    "Kaggle\tCộng đồng chia sẻ dữ liệu, bài toán thực tế và notebook code mẫu.\n",
    "\n",
    "Papers with Code\tChứa dataset liên kết với các nghiên cứu khoa học, chủ yếu về AI & ML.\n",
    "\n",
    "UCI Machine Learning Repository\tKho dữ liệu học máy cổ điển, dễ truy cập, đa dạng lĩnh vực.\n",
    "\n",
    "AWS Open Data\tDữ liệu lớn, dùng cho cloud computing và AI.\n",
    "\n",
    "Google Dataset Search\tCông cụ tìm kiếm tổng hợp nhiều nguồn dataset.\n",
    "\n",
    "Microsoft Datasets\tDữ liệu từ Microsoft về AI, thị giác máy tính, NLP.\n",
    "\n",
    "Reddit Datasets\tCộng đồng chia sẻ nhiều dataset ngẫu nhiên từ người dùng.\n",
    "\n",
    "CMU Libraries\tKho dữ liệu học thuật từ Carnegie Mellon University.\n",
    "\n",
    "GitHub Public Datasets\tDanh sách dataset từ nhiều nguồn trên GitHub.\n",
    "\n",
    "YouTube 8M\tBộ dữ liệu video lớn, hỗ trợ AI & thị giác máy tính.\n",
    "\n",
    "OpenML\tKho dữ liệu học máy mở, hỗ trợ trực tiếp cho ML framework.\n",
    "________________________________________\n",
    "## 2. Bộ dữ liệu công khai trên các nguồn\n",
    "•\tKaggle: Hình ảnh, văn bản, số liệu thống kê, tài chính, NLP, AI.\n",
    "\n",
    "•\tPapers with Code: Chủ yếu về AI, học máy, NLP, thị giác máy tính.\n",
    "\n",
    "•\tUCI Machine Learning: Dữ liệu cổ điển về y tế, tài chính, khoa học xã hội.\n",
    "\n",
    "•\tAWS Open Data: Dữ liệu vệ tinh, y tế, AI, NLP.\n",
    "\n",
    "•\tGoogle Dataset Search: Tổng hợp mọi loại dữ liệu từ nhiều nguồn.\n",
    "\n",
    "•\tMicrosoft Datasets: AI, NLP, dữ liệu thời tiết, y tế.\n",
    "\n",
    "•\tReddit Datasets: Dữ liệu xã hội, mạng xã hội, NLP.\n",
    "\n",
    "•\tCMU Libraries: Dữ liệu nghiên cứu khoa học.\n",
    "\n",
    "•\tGitHub Public Datasets: Tổng hợp nhiều loại dữ liệu từ cộng đồng.\n",
    "\n",
    "•\tYouTube 8M: Video, AI, thị giác máy tính.\n",
    "\n",
    "•\tOpenML: Dữ liệu học máy mở, hỗ trợ AI & NLP.\n",
    "_______________________________________\n",
    "## 3. Dạng dữ liệu công khai\n",
    "•\tCSV, JSON, XML: Kaggle, UCI, Google Dataset Search, OpenML.\n",
    "\n",
    "•\tDữ liệu văn bản (TXT, XML, JSON): Papers with Code, AWS Open Data, Microsoft, Reddit.\n",
    "\n",
    "•\tDữ liệu hình ảnh & video (JPG, PNG, MP4): YouTube 8M, Kaggle, Microsoft.\n",
    "\n",
    "•\tDữ liệu chuỗi thời gian (Time-series): AWS, Microsoft, OpenML.\n",
    "________________________________________\n",
    "## 4. Ưu điểm & Hạn chế\n",
    "Kaggle\tDữ liệu phong phú, có notebook mẫu\tMột số dataset yêu cầu đăng nhập để tải về\n",
    "\n",
    "Papers with Code\tDữ liệu kèm nghiên cứu chi tiết\tChỉ tập trung vào AI & ML\n",
    "\n",
    "UCI Machine Learning\tDữ liệu đơn giản, dễ truy cập\tKhông cập nhật thường xuyên\n",
    "\n",
    "AWS Open Data\tDữ liệu lớn, hỗ trợ AI mạnh mẽ\tCần AWS để xử lý dữ liệu lớn\n",
    "\n",
    "Google Dataset Search\tTìm kiếm được nhiều nguồn dữ liệu\tChất lượng dữ liệu không đồng đều\n",
    "\n",
    "Microsoft Datasets\tDữ liệu AI, NLP chất lượng cao\tKhông phong phú bằng Kaggle\n",
    "\n",
    "Reddit Datasets\tNhiều dữ liệu từ người dùng\tKhông có kiểm duyệt chất lượng\n",
    "\n",
    "CMU Libraries\tNguồn học thuật chất lượng\tKhông có nhiều dữ liệu thực tế\n",
    "\n",
    "GitHub Public Datasets\tTổng hợp nhiều nguồn mở\tCần kiểm tra chất lượng từng dataset\n",
    "\n",
    "YouTube 8M\tLớn, hỗ trợ nghiên cứu video AI\tCần xử lý phức tạp do dung lượng lớn\n",
    "\n",
    "OpenML\tHỗ trợ trực tiếp cho học máy\tDữ liệu không đa dạng bằng Kaggle\n",
    "________________________________________\n",
    "## 5. Nguồn cung cấp dữ liệu cho NLP\n",
    "•\tKaggle\n",
    "\n",
    "•\tPapers with Code\n",
    "\n",
    "•\tAWS Open Data\n",
    "\n",
    "•\tMicrosoft Datasets\n",
    "\n",
    "•\tReddit Datasets\n",
    "\n",
    "•\tOpenML\n",
    "________________________________________\n",
    "## 6. Chọn 1 bộ dữ liệu để tìm hiểu\n",
    "•\tLĩnh vực: Xử lý ngôn ngữ tự nhiên (NLP) - phân tích cảm xúc\n",
    "\n",
    "•\tSố mẫu: 1.6 triệu tweet\n",
    "\n",
    "•\tKích thước: ~200 MB\n",
    "\n",
    "•\tThuộc tính: \n",
    "\n",
    "o\ttarget (cảm xúc: 0 = tiêu cực, 4 = tích cực)\n",
    "\n",
    "o\ttext (nội dung tweet)\n",
    "\n",
    "o\tdate, user, query (các thông tin bổ sung)\n",
    "\n",
    "•\tỨng dụng: Dùng để huấn luyện mô hình phân tích cảm xúc trong NLP.\n",
    "________________________________________\n",
    "## 7. Nguồn cung cấp dữ liệu NLP uy tín khác\n",
    "•\tHugging Face Datasets – Cung cấp nhiều dữ liệu NLP chất lượng cao, tích hợp với thư viện Transformers để huấn luyện mô hình AI. 🚀"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Các nguồn Dataset\n",
    "- Kaggle: https://www.kaggle.com/\n",
    "\n",
    "- Papers with Code: https://paperswithcode.com/datasets\n",
    "\n",
    "- UCI Machine Learning Repository: https://archive.ics.uci.edu/ml/index.php\n",
    "\n",
    "- Registry of Open Data on AWS: https://registry.opendata.aws\n",
    "\n",
    "- Google Dataset Search: https://datasetsearch.research.google.com/\n",
    "\n",
    "- Microsoft Datasets: https://msropendata.com/\n",
    "\n",
    "- Reddit datasets: https://www.reddit.com/r/datasets/top/?sort=top&t=all\n",
    "\n",
    "- CMU Libraries: https://guides.library.cmu.edu/az.php\n",
    "\n",
    "- Public Datasets trên Github: https://github.com/awesomedata/awesome-public-datasets#machinelearning\n",
    "\n",
    "- YouTube Dataset: https://research.google.com/youtube8m/\n",
    "\n",
    "- OpenML: https://www.openml.org/search?type=data&sort=runs&status=active"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
